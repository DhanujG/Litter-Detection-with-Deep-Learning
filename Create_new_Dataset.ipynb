{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd015ac2ca1da7d9bd3bea307d5ea7ff71b4737df7134aa4ab9e215049dfe65c2a6",
   "display_name": "Python 3.8.8 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "15ac2ca1da7d9bd3bea307d5ea7ff71b4737df7134aa4ab9e215049dfe65c2a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import simplejson\n",
    "import pandas as pds  \n",
    "import numpy\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import math\n",
    "import random\n",
    "\n",
    "from __future__ import print_function, division\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "from ROI_Dataset_Generation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "outputting.... into: ./Generated_Data_JSON/custom_trash_environment_data.json\n200\n"
     ]
    }
   ],
   "source": [
    "    json_file = \"./data/annotations.json\"\n",
    "\n",
    "    output_json = \"./Generated_Data_JSON/custom_trash_environment_data.json\"\n",
    "\n",
    "    #513 yields 250 original images read\n",
    "    trash_image_annot = export_modified_json_dataset(json_file, output_json = output_json, export_json=True, num_files = 414)\n",
    "\n",
    "    \n",
    "    print(len(trash_image_annot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1301\n<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "final_dataset = create_custom_boxes(trash_image_annot, output_json = \"./Generated_Data_JSON/roi_boundries_custom_dataset.json\", export_json = True)\n",
    "print(len(final_dataset['image_ids']))\n",
    "\n",
    "print(type(final_dataset['environment'][3]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#print(trash_image_annot[223])\n",
    "\n",
    "image_ids, image_data, trash_labels, environment_labels = export_roi_dataset(final_dataset, trash_image_annot, output_folder = \"./new_data_preprocess/\")\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "93\n93\n93\n47\n93\n"
     ]
    }
   ],
   "source": [
    "print(len(image_data))\n",
    "print(len(image_ids))\n",
    "print(len(trash_labels))\n",
    "print(sum(trash_labels))\n",
    "print(len(environment_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new_data.txt\n",
    "\n",
    "with open(\"new_data.txt\", \"w\") as a:\n",
    "        for path, subdirs, files in os.walk(\"./new_data/\"):\n",
    "            for filename in files:\n",
    "                #f = os.path.join(path, filename)\n",
    "                a.write(str(filename) + \"\\n\") \n",
    "    # return image_ids, image_data, trash_labels, environment_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "outputting.... into: ./Generated_Data_JSON/custom_trash_environment_data.json\n",
      "Created Data Subset Json....\n",
      "91\n",
      "Created New ROI Box Boundries JSON Data...\n",
      "617\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#run full pipeline\n",
    "data_runner(json_file = \"./data/annotations.json\", export_json = True, num_files = 200, output_data_subset_json = \"./Generated_Data_JSON/custom_trash_environment_data.json\", output_new_dataset_json = \"./Generated_Data_JSON/roi_boundries_custom_dataset.json\", output_data_folder = \"./new_data_trial/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"class CustomTrashDataset(Dataset):\n",
    "    \"\"\"custom Trash Taco dataset for 498.\"\"\"\n",
    "\n",
    "    def __init__(self, image_data, image_ids, trash_labels, environment_labels):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            #all lists -> image_data is list of numpy_arrays images 3d\n",
    "        \"\"\"\n",
    "        self.image_data = image_data\n",
    "        self.image_ids = image_ids\n",
    "        self.trash_labels = trash_labels\n",
    "        self.environment_labels = environment_labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.trash_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "\n",
    "        get_im_id = self.image_ids[idx]\n",
    "        get_im_data = self.image_data[idx]\n",
    "        get_trash_label = self.trash_labels\n",
    "        get_environment_label = self.environment_labels\n",
    "\n",
    "        \n",
    "        sample = {'image_id': get_im_id, 'image_data': get_im_data, 'trash_label' : get_trash_label, 'environment_label' : get_environment_label}\n",
    "        return sample\"\"\"\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prettify the original json file\n",
    "filename = open(\"./data/annotations.json\",)\n",
    "\n",
    "annot= json.load(filename)\n",
    "\n",
    "fout = open(\"./data/annotations_clean.json\",\"w\")\n",
    "fout.write(simplejson.dumps(annot, indent = 4, sort_keys = True))\n",
    "fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}